# Projet Deep Learning - Classification MNIST avec PyTorch & VAT

Ce projet impl√©mente un mod√®le de classification d‚Äôimages bas√© sur le dataset **MNIST**, en combinant **apprentissage supervis√©** et **apprentissage semi-supervis√©** avec la technique de **Virtual Adversarial Training (VAT)**.  
Le projet a √©t√© structur√© de mani√®re modulaire et est √©quip√© de tests, CI/CD et d‚Äôun environnement Dockeris√©.

---

## Objectifs

- Entra√Æner un mod√®le robuste avec **peu de donn√©es √©tiquet√©es** (100 images, soit 10 par classe).
- Exploiter les donn√©es non-√©tiquet√©es via **VAT**, une m√©thode d‚Äô**apprentissage semi-supervis√©**.
- Obtenir une bonne g√©n√©ralisation avec peu de supervision explicite.
- Int√©grer une pipeline de test et de qualit√© de code.

---

## Contenu du projet

Le projet comprend :

- **`src/`** : Code source principal avec les modules pour la gestion des donn√©es, la d√©finition des mod√®les, l‚Äôentra√Ænement avec VAT, et l‚Äôimpl√©mentation de la Virtual Adversarial Training.
- **`tests/`** : Tests unitaires r√©alis√©s avec `pytest` pour valider chaque composant.
- **`notebooks/** : Notebooks Jupyter illustrant le pipeline complet, de la pr√©paration des donn√©es √† l‚Äô√©valuation.
- **`best_model.pth`** : Poids sauvegard√©s du meilleur mod√®le entra√Æn√©.
- **`.github/workflows/ci.yml`** : Configuration GitHub Actions pour l‚Äôint√©gration continue (tests et linting).
- **`Dockerfile`** : Environnement Docker assurant la portabilit√© et la reproductibilit√©.
- **`requirements.txt`** : Liste des d√©pendances Python n√©cessaires.
- **`README.md`** : Ce document d√©crivant le projet et son utilisation.

---

## üß™ M√©thodologie

### üî∏ Donn√©es
- **MNIST** : 28√ó28 pixels, chiffres manuscrits.
- 100 √©chantillons √©tiquet√©s (10 par classe).
- Reste utilis√© comme donn√©es non-√©tiquet√©es.
- Jeu de test standard.

### üî∏ Mod√®les
- `SimpleCNNWithDropout` : un petit CNN avec Dropout.
- `PretrainedResNetForMNIST` : adaptation de ResNet18 (ImageNet ‚Üí MNIST).
- `PretrainedMobileNetForMNIST` : adaptation de MobileNetV2.

### üî∏ Apprentissage semi-supervis√© avec VAT
- La **Virtual Adversarial Loss** est utilis√©e pour guider l'entra√Ænement sur les donn√©es non √©tiquet√©es.
- La fonction `virtual_adversarial_loss` est d√©finie dans `src/vat.py`.

---

## ‚öôÔ∏è Environnement & Linting

Le projet utilise :

- **Python 3.11**
- Linting avec :
  - [`flake8`](https://flake8.pycqa.org/)
  - [`black`](https://black.readthedocs.io/)
  - [`isort`](https://pycqa.github.io/isort/)
  - [`mypy`](https://mypy.readthedocs.io/)
- Tests unitaires avec `pytest`

### üß™ Ex√©cuter les tests :
pytest --disable-warnings

---
### Verifier le code:
flake8 src/ tests/
black --check .
isort --check-only .
mypy src/

### Int√©gration Continue (CI)
Une action GitHub automatique (.github/workflows/ci.yml) :
installe les d√©pendances
v√©rifie la qualit√© du code
ex√©cute les tests unitaires
Elle se d√©clenche sur chaque push ou pull request vers main.

### Docker
docker build -t mnist-vat .
docker run -it mnist-vat

### Installation locale
git clone https://github.com/ton-repo/deep-learning-vat.git
cd deep-learning-vat
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

## ‚öôÔ∏è Technologies utilis√©es

- [PyTorch](https://pytorch.org/)
- Torch
- NumPy
- matplotlib
- scikit-learn

## Auteurs

- **Aymane Mimoun**
- **Mohtadi Hammami**
- **Alexandre Combeau**

Master Data Science - Universit√© Paris-Saclay 2025
